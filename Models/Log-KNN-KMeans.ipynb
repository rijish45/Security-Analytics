{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def most_common(row):\n",
    "    return max(set(row), key=row.count)\n",
    "\n",
    "def get_seconds(row):\n",
    "    return row.second\n",
    "\n",
    "def sort_dt(row):\n",
    "    return sorted(row)\n",
    "\n",
    "def get_td_mean(row):\n",
    "    td = 0\n",
    "    if len(row) > 2:\n",
    "        for i in range (0,len(row)-1):\n",
    "            td += row[i+1]-row[i]\n",
    "        return td/(len(row)-1)\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def get_td_sd(row):\n",
    "    sd = 0\n",
    "    new_list = []\n",
    "    if len(row) > 2:\n",
    "        for i in range (0,len(row)-1):\n",
    "            new_list.append(row[i+1]-row[i])\n",
    "        return statistics.stdev(new_list)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def rem_dups(arr):\n",
    "    myset = set(arr)\n",
    "    return list(myset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "data = pd.read_csv(\"Actual-Data/stingar_full-20190523.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['d_time'] = pd.to_datetime(data['d_time']).values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped_td = data[['src_ip','d_time']].groupby('src_ip',as_index = False).agg({'d_time':lambda x: x.tolist()})\n",
    "data_grouped_td['d_time'] = data_grouped_td['d_time'].apply(sort_dt)\n",
    "data_grouped_td['d_time'] = data_grouped_td['d_time'].apply(get_td_mean)\n",
    "data_grouped_td['d_time'] = pd.to_datetime(data_grouped_td['d_time'], unit='ns')\n",
    "data_grouped_td['d_time'] = data_grouped_td['d_time'].apply(get_seconds)\n",
    "data_grouped_td = data_grouped_td.rename({'d_time':'mean_time_difference'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped_sd = data[['src_ip','d_time']].groupby('src_ip',as_index = False).agg({'d_time':lambda x: x.tolist()})\n",
    "data_grouped_sd['d_time'] = data_grouped_sd['d_time'].apply(sort_dt)\n",
    "data_grouped_sd['d_time'] = data_grouped_sd['d_time'].apply(get_td_sd)\n",
    "data_grouped_sd['d_time'] = pd.to_datetime(data_grouped_sd['d_time'], unit='ns')\n",
    "data_grouped_sd['d_time'] = data_grouped_sd['d_time'].apply(get_seconds)\n",
    "data_grouped_sd = data_grouped_sd.rename({'d_time':'sd_time_difference'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data[['src_ip','d_time']].groupby('src_ip',as_index = False).agg({'d_time':np.mean})\n",
    "data_grouped['d_time'] = pd.to_datetime(data_grouped['d_time'], unit='ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped1 = data[['src_ip','d_time']].groupby('src_ip',as_index = False).agg({'d_time':np.std})\n",
    "data_grouped1['d_time'] = pd.to_datetime(data_grouped1['d_time'], unit='ns')\n",
    "data_grouped1['d_time'] = data_grouped1['d_time'].apply(get_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped2 = data[['sensor','src_ip']].groupby('src_ip',as_index = False).agg({'sensor':lambda x: x.tolist()})\n",
    "data_grouped2['most_common_sensor'] = data_grouped2['sensor'].apply(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_grouped.merge(data_grouped1, left_on='src_ip', right_on='src_ip')\n",
    "data_final = data_final.merge(data_grouped_td,left_on='src_ip', right_on='src_ip')\n",
    "data_final = data_final.merge(data_grouped_sd,left_on='src_ip', right_on='src_ip')\n",
    "data_final = data_final.merge(data_grouped2,left_on='src_ip', right_on='src_ip')\n",
    "data_final = data_final.rename({'d_time_x':'mean_time_of_attack','d_time_y':'sd_time_of_attack','sensor':'all_sensors'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Check the sensors column and see how data gets stored\n",
    "\n",
    "data_final['all_sensors'] = data_final['all_sensors'].apply(rem_dups)\n",
    "data_final['all_sensors'].iloc[1659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final[\"sensor_number\"] = data_final[\"all_sensors\"].apply(len)\n",
    "data_final.drop([\"mean_time_of_attack\", \"sd_time_of_attack\"], axis = 1)\n",
    "data_final.drop([\"mean_time_of_attack\", \"sd_time_of_attack\", \"all_sensors\", \"most_common_sensor\"], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['sensor_number'].value_counts()\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data[[\"ssh_username\", \"src_ip\"]].dropna()\n",
    "new[\"length_username\"] = new[\"ssh_username\"].apply(len)\n",
    "user_length = new.groupby(\"src_ip\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = pd.merge(user_length, data_final, how = \"outer\", on = \"src_ip\")\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['length_username'].fillna(value = current['length_username'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_command = data[['src_ip', 'command']]\n",
    "new_command.dropna(inplace = True)\n",
    "new_command['length_command'] = new_command['command'].apply(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = new_command.groupby('src_ip').mean()\n",
    "current = pd.merge(current, feature, how = 'outer', on = \"src_ip\")\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['length_command'].fillna(value = current['length_command'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['app'].value_counts()\n",
    "counts = data['app'].value_counts()\n",
    "res = data[~data['app'].isin(counts[counts < 27].index)]\n",
    "res['app'].value_counts()\n",
    "honeypot = res[['app', 'src_ip']]\n",
    "honeypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honeypot['app'].value_counts()\n",
    "honeypot.groupby('src_ip').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_current = pd.merge(current, honeypot, how = 'inner', on = 'src_ip')\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.groupby('src_ip')[['src_ip', 'app']].head()\n",
    "temp = dat.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let = pd.get_dummies(temp['app'])\n",
    "let.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = pd.concat([let,temp], axis = 1)\n",
    "det['app'].value_counts()\n",
    "counts = det['app'].value_counts()\n",
    "det = det[~det['app'].isin(counts[counts < 100].index)]\n",
    "det['app'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current.drop_duplicates('src_ip', inplace = True)\n",
    "current\n",
    "head = data[['src_ip', 'app']]\n",
    "head = head.groupby('src_ip').count()\n",
    "head.reset_index(inplace = True)\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = pd.merge(current, head, how = 'inner', on = 'src_ip')\n",
    "current.rename(columns={'app':'daily_frequency'}, inplace=True)\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current.drop(['app_y'], axis = 1, inplace = True)\n",
    "#current.drop(['app'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data[['src_ip', 'ssh_password']]\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[['src_ip', 'ssh_password']]\n",
    "new_data.head()\n",
    "new_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['length_password'] = new_data['ssh_password'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop(['ssh_password'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop_duplicates(inplace= True)\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = pd.merge(current, new_data, how = 'outer', on = 'src_ip')\n",
    "current['length_password'].fillna(value = current['length_password'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current.drop_duplicates(inplace= True)\n",
    "current.drop_duplicates('src_ip', inplace= True)\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_t = data.groupby('src_ip')['dest_port'].nunique()\n",
    "new_dat_t = dat_t.reset_index()\n",
    "new_dat_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current = pd.merge(new_dat_t, current, how = 'inner', on = 'src_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current.rename(columns={'dest_port':'dest_port_number'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['dest_port_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['length_command'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['length_password'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current['length_username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = data[['src_ip', 'signature']]\n",
    "new_frame.info()\n",
    "new_frame['signature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame.drop_duplicates(subset = \"src_ip\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.merge(current, new_frame, on = 'src_ip', how = 'inner')\n",
    "current_df.info()\n",
    "dummy = pd.get_dummies(current_df['signature'], drop_first = True)\n",
    "cur = pd.concat([current_df,dummy], axis = 1)\n",
    "cur.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.drop(['SSH session on cowrie honeypot'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honeypot['app'].value_counts()\n",
    "honeypot.drop_duplicates(subset = 'src_ip', inplace= True)\n",
    "honeypot['app'].value_counts()\n",
    "cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_curr = pd.merge(cur, honeypot, on = 'src_ip', how = 'inner')\n",
    "new_curr.drop(['command attempted on cowrie honeypot'], axis =1, inplace = True)\n",
    "new_curr['signature'].value_counts()\n",
    "new_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Algorithm\n",
    "=================\n",
    "\n",
    "K-Means Algorithm\n",
    "-----------------------\n",
    "\n",
    "The k-means algorithm belongs to the category of prototype-based clustering.\n",
    "Prototype-based clustering means that each cluster is represented by a prototype, which can either be the centroid (average) of similar points with continuous features, or the medoid (the most representative or most frequently occurring point) in the case of categorical features.\n",
    "While k-means is very good at identifying clusters with a spherical shape, one of the drawbacks of this clustering algorithm is that we have to specify the number of clusters, k, a priori. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = new_curr['app']\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature = new_curr.drop(['signature'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize = (8,5))\n",
    "sns.scatterplot('length_username', 'length_password', hue = 'app', data = feature)\n",
    "axes.set(xlabel='Length of Username', ylabel='Length of Password')\n",
    "axes.set_xlim([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize = (8,5))\n",
    "sns.heatmap(feature.corr(), annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature['app'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dat = feature.drop(['src_ip','app'], axis = 1)\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(dat)\n",
    "y_kmeans = kmeans.predict(dat)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize = (8,4))\n",
    "plt.scatter(dat.iloc[:, 1], dat.iloc[:, 7], c = y_kmeans, s = 50, cmap='rainbow')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 1], centers[:, 7], c='black', s = 100, alpha = 1)\n",
    "axes.set_xlim([1,10])\n",
    "axes.set_xlabel('Length of Username')\n",
    "axes.set_ylabel('Length of Password')\n",
    "axes.set_title('K-Means with  = 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(dat)\n",
    "    kmeanModel.fit(dat)\n",
    "    distortions.append(sum(np.min(cdist(dat, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / dat.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "fig, axes = plt.subplots(1,1, figsize = (8,5))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = feature.drop(['app', 'src_ip'], axis = 1)\n",
    "kmeans = KMeans(n_clusters = 8)\n",
    "kmeans.fit(dat)\n",
    "y_kmeans = kmeans.predict(dat)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize = (8,4))\n",
    "plt.scatter(dat.iloc[:, 1], dat.iloc[:, 7], c = y_kmeans, s = 50, cmap='rainbow')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 1], centers[:, 7], c='black', s=100, alpha=1);\n",
    "axes.set_xlim([1,10])\n",
    "axes.set_xlabel('Length of Username')\n",
    "axes.set_ylabel('Length of Password')\n",
    "axes.set_title('K-Means with K = 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dion = feature[feature['app'] == 'dionaea']\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dat = dion.drop(['src_ip','app'], axis = 1)\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(dat)\n",
    "y_kmeans = kmeans.predict(dat)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize = (8,5))\n",
    "plt.scatter(dat.iloc[:, 1], dat.iloc[:, 7], c = y_kmeans, s = 50, cmap='rainbow')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 1], centers[:, 7], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(dat)\n",
    "    kmeanModel.fit(dat)\n",
    "    distortions.append(sum(np.min(cdist(dat, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / dat.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "fig, axes = plt.subplots(1,1, figsize = (8,5))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5)\n",
    "kmeans.fit(dat)\n",
    "y_kmeans = kmeans.predict(dat)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize = (8,5))\n",
    "plt.scatter(dat.iloc[:, 1], dat.iloc[:, 7], c = y_kmeans, s = 50, cmap='rainbow')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 1], centers[:, 7], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neighbourhood\n",
    "---------------------\n",
    "\n",
    "\n",
    "The KNN algorithm assumes that similar things exist in close proximity The KNN algorithm hinges on this assumption being true enough for the algorithm to be useful. KNN captures the idea of similarity (sometimes called distance, proximity, or closeness) with some mathematics we might have learned in our childhoodâ€” calculating the distance between points on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = new_curr.drop(['signature'], axis = 1)\n",
    "count_t = dem['app'].value_counts()\n",
    "result = dem[~new_curr['app'].isin(counts[counts < 1000].index)]\n",
    "result['app'].value_counts()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(data = result, columns = ['app'], drop_first = True)\n",
    "dummy.drop(['src_ip'], axis =1 , inplace = True)\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dummy.drop(['app_dionaea'], axis =1))\n",
    "scaled_features = scaler.transform(dummy.drop(['app_dionaea'], axis =1))\n",
    "df_feat = pd.DataFrame(scaled_features,columns = dummy.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat['length_command'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,dummy['app_dionaea'],\n",
    "                                                    test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "c = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(c, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "visualizer = ClassificationReport(knn)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.score(X_test, y_test) \n",
    "visualizer.poof()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "visualizer = ClassificationReport(knn)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.score(X_test, y_test) \n",
    "visualizer.poof()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "\n",
    "y_scores = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "-----------------------\n",
    "\n",
    "Logistic Regression is generally used for classification purposes. Unlike Linear Regression, the dependent variable can take a limited number of values only i.e, the dependent variable is categorical. When the number of possible outcomes is only two it is called Binary Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frame = data[['src_ip', 'tags']]\n",
    "my_frame['tags'].fillna(value = 'cloud,', inplace = True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frame['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    index = row.find(\",\")\n",
    "    return row[0:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frame['tags'] = my_frame['tags'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frame['tags'].value_counts()\n",
    "sns.countplot(my_frame['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = my_frame.drop_duplicates(subset='src_ip')\n",
    "curr_doc = pd.merge(result, new_frame, how = 'inner', on = 'src_ip')\n",
    "curr_doc.drop(['src_ip', 'app'], axis = 1, inplace = True)\n",
    "curr_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (8,5))\n",
    "df_tags = pd.get_dummies(curr_doc['tags'], drop_first = True )\n",
    "df_new = pd.concat([curr_doc, df_tags], axis=1)\n",
    "df_new.drop(['tags'], axis = 1, inplace = True)\n",
    "df_new.rename(columns={'localnet':'tag'}, inplace = True)\n",
    "sns.countplot(df_new['tag'])\n",
    "axes.set_title('Count-plot based on type of Honeypot')\n",
    "axes.set_xlabel(\"Honeypot Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop('tag', axis=1)\n",
    "y = df_new['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "parameters = model.coef_\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 5)\n",
    "\n",
    "y_scores = model.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "visualizer = ClassificationReport(model)\n",
    "visualizer.fit(X_train, y_train)  \n",
    "visualizer.score(X_test, y_test) \n",
    "visualizer.poof()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
